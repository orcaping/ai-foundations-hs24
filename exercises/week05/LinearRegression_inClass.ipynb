{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c4d023c",
   "metadata": {},
   "source": [
    "# Regression\n",
    "The goal of this notebook is to familiarize you with different aspects of linear regression. We study:   \n",
    "- linear regression  \n",
    "- polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b0ec09",
   "metadata": {},
   "source": [
    "# PART 1: Linear Regression\n",
    "(in class exercises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa8be8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import clear_output, display, HTML\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015fbbb0",
   "metadata": {},
   "source": [
    "# The data\n",
    "We have N=5 data points (x,y) given as two vectors X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "670edc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n"
     ]
    }
   ],
   "source": [
    "data_X = np.array([-4,   -2,   1,  2.5,  3.9])\n",
    "data_Y = np.array([-0.9, -0.4, 1.7, 1.5,  2.05])\n",
    "print(data_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78e8a665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Data')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(data_X, data_Y, '--og', linewidth = 1, markersize=10)\n",
    "plt.grid()\n",
    "plt.axhline(y=0, color='k')\n",
    "plt.axvline(x=0, color='k')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dbd991",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "The goal of the model is to take a value x and predict $\\hat{y}$. We use the 'hat' symbol to denote an estimated (predicted) value:\n",
    "\n",
    "$$\n",
    "\\hat{y} = a \\cdot x + b\n",
    "$$\n",
    "\n",
    "\n",
    "In Python, we can use the LinearRegression class from the scikit-learn library to express a linear model.  <br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "We will use sciki-learn later in this notebook. First we do fit the data manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f759b7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "[-1.    0.    1.5   2.25  2.95]\n"
     ]
    }
   ],
   "source": [
    "lin_function = lambda x, a, b : a*x+b\n",
    "\n",
    "# evaluate the model:\n",
    "y = lin_function(-4, 0.5, 1.0)\n",
    "print(y)\n",
    "\n",
    "#We can pass a vector (array) to the lambda expression \n",
    "Y = lin_function(data_X, 0.5, 1.0)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8f5dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (interactive) visualization we need to wrap the model and the MSE calculation\n",
    "# into a more complicated function. \n",
    "# You can skip this code.\n",
    "\n",
    "\n",
    "def plt_linear_model(a = 0.1, b = 0.2, X = data_X, Y = data_Y, show_error_squares=False):\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = plt.axes()\n",
    "    \n",
    "    y = lin_function(X, a, b)\n",
    "\n",
    "    if show_error_squares:\n",
    "        ax.plot(X, y, '-xb', linewidth=2)\n",
    "    else:\n",
    "        ax.plot(X, y, '-b', linewidth=2)\n",
    "        \n",
    "    ax.plot(X, Y, '--og', linewidth=1)\n",
    "    ax.axhline(y=0, color='tab:gray')\n",
    "    ax.axvline(x=0, color='tab:gray')\n",
    "    ax.grid()\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    N = len(X)\n",
    "\n",
    "    if show_error_squares:\n",
    "        Esum = 0.\n",
    "        for i in range(N):\n",
    "            xi = X[i]\n",
    "            yi = Y[i]\n",
    "            y_hat = lin_function(xi, a, b)\n",
    "            err = yi-y_hat # difference between data and model estimate\n",
    "            Esum += (err**2)/2.\n",
    "            if abs(err) > 0.01 :\n",
    "                sq = plt.Rectangle( (xi, yi), abs(err), -err , alpha=0.2, color='r')\n",
    "                ax.add_patch(sq)\n",
    "                ax.plot([xi, xi], [yi, y_hat], linewidth=3, color='r')\n",
    "        ax.set_title(\"Linear Model Params: a={:.3}, b={:.3}\\nMean squared error (MSE) = {:.4f}\".format(a, b, Esum/N))\n",
    "    else:\n",
    "        ax.set_title(\"Linear Model Params: a={:.3}, b={:.3}\".format(a, b))\n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2351620d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, 0.5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guess some value for slope (parameter a) and intercept (parameter b).\n",
    "# Compare your guess with the data:\n",
    "plt_linear_model(a = 0.1, b = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22079ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2, -0.2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plt_linear_model example 2\n",
    "plt_linear_model(a = 0.2, b = -0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79901396",
   "metadata": {},
   "source": [
    "## Interactive, manual fitting\n",
    "\n",
    "Use the sliders to find the line which best approximates the given datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc362c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525178e7bed642698f9d1d319582695e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=-0.1, description='a', max=1.0, min=-1.0, step=0.02), FloatSlider(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plt_linear_model(a=0.1, b=0.2, X=array([-4. , -2. ,  1. ,  2.5,  3.9]), Y=array([-0.9 , -0.4 ,  1.7 ,  1.5 ,  2.05]), show_error_squares=False)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = interact(plt_linear_model, \n",
    "             a=widgets.FloatSlider(min=-1.0, max=1.0, step=0.02, value=-0.1),\n",
    "             b=widgets.FloatSlider(min=-2.0, max=2.0, step=0.02, value=+1.5),\n",
    "             X=fixed(data_X),\n",
    "             Y=fixed(data_Y),\n",
    "             show_error_squares = fixed(False))\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a61ccc",
   "metadata": {},
   "source": [
    "# Evaluating your fit: introducing the Loss Function\n",
    "\n",
    "How good does your linear model approximate the data? To answer this question, we need a way to measure the \"goodness\" of the fit. A common quantity to look at, are the squared errors:\n",
    "\n",
    "For each data point $(x_i, y_i)$ we compare the given value $y_i$ with the value $\\hat{y}_i$ predicted by the model. The total error is calculated as the sum (over N given data points) of the squared differences, divided by N. For reason that become clear later, the error is (often) divided by 2.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{y}_i &= a \\cdot x_i + b \\\\\n",
    "e_i &= y_i - \\hat{y}_i   \\\\\n",
    "E &= \\frac{1}{2N}\\sum_{i=1}^N e_i^2 \\\\\n",
    "&= \\frac{1}{2N}\\sum_{i=1}^N (\\hat{y} - (a \\cdot x_i + b) )^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This error is known as the **Mean Squared Error (MSE)** (divided by 2). We can visualize the squared errors $e_i^2$ for different model parameters and gain intuition for the error function:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bb5a636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2, 0.5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example: plot the model and visualize the loss\n",
    "plt_linear_model(a=0.2, b= 0.5,show_error_squares=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86c05c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 1.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example 2: \n",
    "plt_linear_model( a=0.5, b=1.0,show_error_squares=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef640302",
   "metadata": {},
   "source": [
    "# Interactive MSE minimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0be2dde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0be1c1a617346b98052f4be34cbf3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.1, description='a', max=0.8, min=-0.5, step=0.02), FloatSlider(valueâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plt_linear_model(a=0.1, b=0.2, X=array([-4. , -2. ,  1. ,  2.5,  3.9]), Y=array([-0.9 , -0.4 ,  1.7 ,  1.5 ,  2.05]), show_error_squares=False)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 3: Using the interactive widget, find the optimal fit\n",
    "\n",
    "w = interact(plt_linear_model, \n",
    "             a=widgets.FloatSlider(min=-0.5, max=0.8, step=0.02, value=0.1),\n",
    "             b=widgets.FloatSlider(min=-1.0, max=1.0, step=0.02, value=0.5),\n",
    "             X=fixed(data_X),\n",
    "             Y=fixed(data_Y),\n",
    "             show_error_squares = fixed(True))\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d2ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26759bc5",
   "metadata": {},
   "source": [
    "## Fitting a linear model with scikit-learn\n",
    "scikit-learn.org is a very useful collection of machine-learning tools. Fitting a linear model to data is very simple.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ba7158",
   "metadata": {},
   "source": [
    "Before applying sklearn, let's inspect the data format. Is X a matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09645def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.  -2.   1.   2.5  3.9]\n",
      "(5,)\n",
      "[[-4. ]\n",
      " [-2. ]\n",
      " [ 1. ]\n",
      " [ 2.5]\n",
      " [ 3.9]]\n",
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "print(data_X)\n",
    "print(data_X.shape)\n",
    "print(data_X.reshape(-1, 1))\n",
    "print(data_X.reshape(-1, 1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "312a67c5-6563-4200-9f71-13be32032a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4. ],\n",
       "       [-2. ],\n",
       "       [ 1. ],\n",
       "       [ 2.5],\n",
       "       [ 3.9]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare the data for the fit. Note the reshape function.\n",
    "data_X_array = data_X.reshape(-1, 1)\n",
    "display(data_X_array)\n",
    "display(data_X_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3e69e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "#YOUR CODE HERE:\n",
    "\n",
    "# create a LinearRegression object:\n",
    "\n",
    "# fit the model to the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5923e24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c3b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330e5c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = lin_model.coef_[0]\n",
    "print(a)\n",
    "b = lin_model.intercept_\n",
    "print(b)\n",
    "# display( (a, b) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cfe983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use the model to predict values.\n",
    "y_hat = lin_model.predict(data_X_array)\n",
    "display(y_hat)\n",
    "display(y_hat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec9a73",
   "metadata": {},
   "source": [
    "We can now anser the initial question (from the slides: for a new x=0.8, what is y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2bc792",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = lin_model.predict([[0.8]])\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ff4231",
   "metadata": {},
   "source": [
    "we can predict multiple y_hat at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd1af5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = lin_model.predict(data_X_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5d6716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the result\n",
    "plt.plot(data_X, y_hat, ':', label=None, color = 'lightgrey')\n",
    "plt.plot(data_X_array, y_hat, 'o', label='$\\hat{y}$')\n",
    "plt.plot(data_X_array, data_Y, 'o', label='data')\n",
    "plt.legend()\n",
    "plt.xlabel('X (Input, independent Variable)')\n",
    "plt.ylabel('Y (Output, dependent Variable)')\n",
    "plt.title('Simple linear regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a0a05f",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "- Calculate the residuals  \n",
    "- plot a histogram of residuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405ddaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c032cc6d",
   "metadata": {},
   "source": [
    "# PART 2: Multiple Linear Regression\n",
    "Download the dataset from Moodle or Kaggle:    \n",
    "https://www.kaggle.com/code/divan0/multiple-linear-regression/data\n",
    "\n",
    "In this example we want to explain the price of an appartement using multiple variables (for example size, number of rooms, etc. That is, we predict one response variable (aka target variable, dependent variable etc) from multiple input variables (aka \"explanatory variables\", feature, independent variables)\n",
    "\n",
    "\n",
    "Note: Multiple Linear Regression is not the same as Multivariate Regression. We study Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8296a326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import seaborn as sb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfee0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_df = pandas.read_csv('kc_house_data.csv')\n",
    "print(house_df.info())\n",
    "house_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0bae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_price_data = house_df[['price', 'bedrooms', 'sqft_living', 'yr_built']]\n",
    "house_price_data = house_price_data.sample(n=5000, random_state=12345, replace=False)\n",
    "# do some cleaning. Here, we do not care about the optimal values. Just remove some data:\n",
    "house_price_data = house_price_data[house_price_data.price.notnull() & (house_price_data.price>100)  & (house_price_data.price < 3e6)]\n",
    "house_price_data = house_price_data[house_price_data.bedrooms.notnull() & (house_price_data.bedrooms >= 1)]\n",
    "house_price_data = house_price_data[house_price_data.price.notnull() & (house_price_data.sqft_living>10)  & (house_price_data.sqft_living < 5000)]\n",
    "house_price_data = house_price_data[house_price_data.yr_built.notnull() & (house_price_data.yr_built>1900)  & (house_price_data.yr_built < 2010)]\n",
    "\n",
    "# head shows the first 5 rows. We use this to verify we correctly loaded the data\n",
    "house_price_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21954355",
   "metadata": {},
   "source": [
    "Before doing any modelling, it's always a good idea to explore the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f2ce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://seaborn.pydata.org/generated/seaborn.pairplot.html\n",
    "sb.pairplot(house_price_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb7468d",
   "metadata": {},
   "source": [
    "### Simple Linear Regression\n",
    "The dependent variable (here price) is explained using only a **single** independent variable: \n",
    "  \n",
    "Model 1:  \n",
    "$price = a_1\\cdot area + intercept_1$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd31f43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b9827",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_linear_regression_model_area = linear_model.LinearRegression()\n",
    "simple_linear_regression_model_area.fit(house_price_data[[ 'sqft_living']],house_price_data['price'])\n",
    "simple_linear_regression_model_area.coef_\n",
    "\n",
    "predicted_price = simple_linear_regression_model_area.predict(house_price_data[[ 'sqft_living']])\n",
    "residuals = predicted_price - house_price_data['price']\n",
    "plt.hist(residuals, bins=100)\n",
    "plt.title('Histogram of residuals')\n",
    "plt.xlabel(\"residual\")\n",
    "plt.ylabel(\"nr of values in bin\")\n",
    "# MSE_sqft_living = np.sum(residuals**2)/residuals.size\n",
    "MSE_sqft_living = mean_squared_error(predicted_price, house_price_data['price'])\n",
    "print('MSE sqft_living model= {}'.format(MSE_sqft_living))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326705ae",
   "metadata": {},
   "source": [
    "### complex model: linear model with 3 independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e325e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_lin_model = linear_model.LinearRegression()\n",
    "\n",
    "X = house_price_data[[ 'bedrooms', 'sqft_living', 'yr_built']]\n",
    "Y = house_price_data['price']\n",
    "\n",
    "multi_lin_model.fit(X,Y)\n",
    "\n",
    "predicted_price = multi_lin_model.predict(house_price_data[['bedrooms', 'sqft_living', 'yr_built']])\n",
    "residuals = predicted_price - house_price_data['price']\n",
    "\n",
    "plt.hist(residuals, bins=100)\n",
    "plt.title('Histogram of residuals')\n",
    "plt.xlabel(\"residual\")\n",
    "plt.ylabel(\"nr of values in bin\")\n",
    "\n",
    "MSE_multiple = np.sum(residuals**2)/residuals.size\n",
    "print('MSE multiple linear regression model= {}'.format(MSE_multiple))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4182c7",
   "metadata": {},
   "source": [
    "model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13d1691",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multi_lin_model.coef_)\n",
    "print(multi_lin_model.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa8f47b",
   "metadata": {},
   "source": [
    "### Questions and Comments  \n",
    "- What is the interpretation of a negative weight/coefficient?  \n",
    "- How do you interprete the intercept ?\n",
    "- Can we compare the weights? Is 'condition' ~30x more important than 'sqft_living' ?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3e6809",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.pairplot(house_price_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d635165b",
   "metadata": {},
   "source": [
    "## Exercise (not now. Exercise session)\n",
    "- Add one more factor to the model.  \n",
    "- Fit the new model  \n",
    "- Calculate the predicted values and plot the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853366e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55426a2f",
   "metadata": {},
   "source": [
    "# PART 3: Polynomial Regression (and feature engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f78d8ef",
   "metadata": {},
   "source": [
    "Is this a linear model:  \n",
    "$y=ax^2 + bx + c$\n",
    "\n",
    "No. But it is **linear in the parameters**  \n",
    "\n",
    "We can apply linear regression to arbitrarily complex models, as long as it is linear in the **unknowns**.  \n",
    "Example, linear in a, b, c:  \n",
    "$y= a \\cdot sin(x) + b \\cdot exp( x) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5d9426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's generate some random data and recover the parameters:\n",
    "# create random number generator. We reuse this instance later\n",
    "rng = default_rng()\n",
    "fancy_function = lambda X, a, b, s=1 : a*X**3 + b*X**2+ rng.normal(loc=0.0, scale=s, size=X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69937258",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-6, 3, num=10)\n",
    "Y = fancy_function(X, 0.2, 1.2, s=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad3a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X,Y, '.')\n",
    "plt.title(\"Data with a non-linear relationship\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3d082c",
   "metadata": {},
   "source": [
    "## Can we still use linear regression to fit a model?\n",
    "- from observation, we assume a relationship of the type $y = ax^3 + bx^2 +cx + d$  \n",
    "- X is known. Therefore we can calculate $x^3$, $x^2$, $x^1$ \n",
    "- How does this differ from the previous example of multiple linear regression, price = f(surface, year_built, ...) ?\n",
    "\n",
    "\n",
    "It doesn't\n",
    "\n",
    "How to proceed:  \n",
    "1. calculate the \"features\".\n",
    "2. apply multiple linear regression to recover the feature weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055505af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = np.column_stack((X**3, X**2, X))\n",
    "print(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd5073",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model_polynomial = linear_model.LinearRegression()\n",
    "lin_model_polynomial.fit(X_features,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d5f257",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lin_model_polynomial.coef_)\n",
    "print(lin_model_polynomial.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b413244f",
   "metadata": {},
   "source": [
    "## Remarks:\n",
    "- For Polynomials, check out numpy.polyfit  \n",
    "  https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html  \n",
    "- The approach shown here is more general. It also works if we create arbitrary complex features f(X).\n",
    "- calculating features from data is called **feature engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0fc0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.polyfit(X, Y, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffd6ba2",
   "metadata": {},
   "source": [
    "## Exercise feature engineering\n",
    "\n",
    "Go back to the housing data. Someone made the hypothesis that the prices for large appartements grow superlinearly. Make a simple check for this hypothesis:\n",
    "\n",
    "Compare the MSE of two simple linear models, each with only one feature:\n",
    "- model 1: price = w1 x sqft_living + w0  \n",
    "- model 2: price = w1 x (sqft_living^1.5) + w0. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d3e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca9e79-af4e-45a8-ae5b-207f5f05744d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aifoundation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
